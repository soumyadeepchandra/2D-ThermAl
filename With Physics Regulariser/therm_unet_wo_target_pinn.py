# -*- coding: utf-8 -*-
"""Therm_UNet.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1V7uuS3JbE0Nianw8ySQ619r2zV66qeqG
"""


import os
import glob
import numpy as np
import matplotlib.pylab as plt
from PIL import Image
import random
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
import albumentations as A

# Check for GPU availability
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')



transform_train = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
])

albumentations_transform = A.Compose([
    A.Rotate(limit=45, p=0.5),
    A.HorizontalFlip(p=0.5),
    A.Flip(p=0.5),
], additional_targets={"image2": "image"})

transform_test = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
])

class ThermDataset(Dataset): #For training
    def __init__(self, input_image_paths, gt_image_paths, transform=False, study = 'train'): #transform = true in train, false in test
        self.input_image_paths = input_image_paths
        self.gt_image_paths = gt_image_paths
        self.transform = transform
        self.study = study
        # print(self.input_image_paths)

    def __len__(self):
        return len(self.input_image_paths)

    #idx is handled auto, u dont need to specify
    def __getitem__(self, idx):
        input_image_filepath = self.input_image_paths[idx]
        output_image_filepath = self.gt_image_paths[idx]
        image_input = Image.open(input_image_filepath).convert("RGB")
        image_output = Image.open(output_image_filepath).convert("RGB")
        image_input = image_input.resize((224,224))
        image_output = image_output.resize((224,224))
        # print(input_image_filepath)
        # print(output_image_filepath)
        # print(image_output.shape)

        if self.study == 'train':
            image_np = np.array(image_input)
            image_np2 = np.array(image_output)
            augmented = albumentations_transform(image=image_np, image2=image_np2)
            image_np_transformed = augmented['image']
            image_input = Image.fromarray(image_np_transformed)
            image_np_transformed2 = augmented['image2']
            image_output = Image.fromarray(image_np_transformed2)


        # Both input and output are transformed
        if self.transform is not None:
            image_input = self.transform(image_input)
            image_output = self.transform(image_output)

        return image_input, image_output, input_image_filepath, output_image_filepath

class ThermDataset2(Dataset): # For inference
    def __init__(self, input_image_paths, gt_image_paths, transform=False, study = 'train'): #transform = true in train, false in test
        self.input_image_paths = input_image_paths
        self.gt_image_paths = gt_image_paths
        self.transform = transform
        self.study = study
        # print(self.input_image_paths)

    def __len__(self):
        return len(self.input_image_paths)

    #idx is handled auto, u dont need to specify
    def __getitem__(self, idx):
        input_image_filepath = self.input_image_paths[idx]
        output_image_filepath = self.gt_image_paths[idx]
        image_input = Image.open(input_image_filepath).convert("RGB")
        image_output = Image.open(output_image_filepath).convert("RGB")
        image_input = image_input.resize((224,224))
        image_output = image_output.resize((224,224))


        # Both input and output are transformed
        if self.transform is not None:
            image_input = self.transform(image_input)
            image_output = self.transform(image_output)

        return image_input, image_output, input_image_filepath, output_image_filepath


def double_conv2d(in_channel, out_channel):
    """
    (convolution => [BN] => ReLU) * 2
    """
    convLayer = nn.Sequential(
        nn.Conv2d(in_channel, out_channel, kernel_size=3, padding=1),
        nn.BatchNorm2d(out_channel),
        nn.ReLU(inplace=True),
        nn.Conv2d(out_channel, out_channel, kernel_size=3, padding=1),
        nn.BatchNorm2d(out_channel),
        nn.ReLU(inplace=True)
    )
    return convLayer


class DiffUnet(nn.Module):
    def __init__(self, input_channels=3):
        super(DiffUnet, self).__init__()
        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)

        self.downConvLayer_1 = double_conv2d(input_channels, 48)
        self.downConvLayer_2 = double_conv2d(48, 96)
        self.downConvLayer_3 = double_conv2d(96, 192)
        self.downConvLayer_4 = double_conv2d(192, 384)
        self.downConvLayer_5 = double_conv2d(384, 768)

        self.upTransConv1 = nn.ConvTranspose2d(in_channels=768, out_channels=384, kernel_size=(2, 2), stride=(2, 2))
        self.upConvLayer_1 = double_conv2d(768, 384)

        self.upTransConv2 = nn.ConvTranspose2d(in_channels=384, out_channels=192, kernel_size=(2, 2), stride=(2, 2))
        self.upConvLayer_2 = double_conv2d(384, 192)

        self.upTransConv3 = nn.ConvTranspose2d(in_channels=192, out_channels=96, kernel_size=(2, 2), stride=(2, 2))
        self.upConvLayer_3 = double_conv2d(192, 96)

        self.upTransConv4 = nn.ConvTranspose2d(in_channels=96, out_channels=48, kernel_size=(2, 2), stride=(2, 2))
        self.upConvLayer_4 = double_conv2d(96, 48)

        self.out = nn.Conv2d(in_channels=48, out_channels=3, kernel_size=(1,1)) #out_channels 4 number ta n_classes, 4CH, for 2CH set it=2

    def forward(self, image):
        """
        image shape: batch_size, channel, height, width
        """
        """
        Encoder
        """
        #print(image.shape)
        # Layer1
        d1_out = self.downConvLayer_1(image)
        #print(d1_out.shape)

        # Layer2
        d2_max_pool_out = self.max_pool(d1_out)
        d2_out = self.downConvLayer_2(d2_max_pool_out)
        #print(d2_out.shape)

        # Layer3
        d3_max_pool_out = self.max_pool(d2_out)
        d3_out = self.downConvLayer_3(d3_max_pool_out)
        #print(d1_out.shape)

        # Layer4
        d4_max_pool_out = self.max_pool(d3_out)
        d4_out = self.downConvLayer_4(d4_max_pool_out)
        #print(d4_out.shape)

        # Layer5
        d5_max_pool_out = self.max_pool(d4_out)
        d5_out = self.downConvLayer_5(d5_max_pool_out)
        #print(d5_out.shape)

        """
        Decoder
        """
        up_sampling1 = self.upTransConv1(d5_out)
        u1_out = self.upConvLayer_1(torch.cat([d4_out, up_sampling1], axis=1))
        #print(u1_out.shape)

        up_sampling2 = self.upTransConv2(u1_out)
        u2_out = self.upConvLayer_2(torch.cat([d3_out, up_sampling2], axis=1))
        #print(u2_out.shape)

        up_sampling3 = self.upTransConv3(u2_out)
        u3_out = self.upConvLayer_3(torch.cat([d2_out, up_sampling3], axis=1))
        #print(u3_out.shape)

        up_sampling4 = self.upTransConv4(u3_out)
        u4_out = self.upConvLayer_4(torch.cat([d1_out, up_sampling4], axis=1))
        #print(u4_out.shape)

        final_out = self.out(u4_out)
        #print(final_out.shape)
        return final_out

# Function to calculate the Laplacian (second derivative)
def laplacian(input_image):
    # Gradient in x, y, and z directions
    grad_x = torch.gradient(input_image, dim=2)[0]  # Gradient in x-direction
    grad_y = torch.gradient(input_image, dim=3)[0]  # Gradient in y-direction
    grad_xx = torch.gradient(grad_x, dim=2)[0]  # Second derivative in x
    grad_yy = torch.gradient(grad_y, dim=3)[0]  # Second derivative in y
    laplacian = grad_xx + grad_yy
    return laplacian

# Physics-Informed Loss Function based on Heat Diffusion
def physics_informed_loss(model_output, alpha, lambda_reg):
    # Calculate the Laplacian of the model's output (thermal prediction)
    laplacian_output = laplacian(model_output)
    
    # Heat diffusion equation residual: (∂T/∂t - α∇²T)
    residual = torch.abs(model_output - alpha * laplacian_output)  # Residual term
    
    # Physics-informed loss term (scaled by regularizer lambda)
    loss_term = torch.mean(residual ** 2)
    return lambda_reg * loss_term


def test(image_path, output_path):
    # image = Image.open(image_path).convert("RGB")
    # output = Image.open(output_path).convert("RGB")

    # Convert images to numpy arrays
    image1_array = np.array(image_path)
    image2_array = np.array(output_path)

    diff = 0
    # Check if the dimensions are the same
    if image1_array.shape == image2_array.shape:
        # Compute the difference
        difference = np.abs(image1_array - image2_array)
        # print(difference.shape)
        diff = np.sum(difference)/(224*224*3)

    return diff

def calculate_iou_for_single_image(input_image, output_image):
  # Calculate the intersection and union of the two images
  intersection = np.logical_and(input_image, output_image)
  union = np.logical_or(input_image, output_image)

  # Calculate the IOU
  iou = np.sum(intersection) / np.sum(union)

  return iou

def get_model_size(model):
    param_size = 0
    param_count = 0
    for param in model.parameters():
        param_size += param.nelement() * param.element_size()
        param_count += param.nelement()
    param_size_MB = param_size / (1024 ** 2)
    return param_size_MB, param_count


# 001->003->006->010->020->041
############################# Stage 1 -> 001 to 003 #######################################
train_input_image_paths_root = [
    F"/home/nano01/a/chand133/ThermAI/Dataset/Train/Input/001/",
    F"/home/nano01/a/chand133/ThermAI/Dataset/Train/Input/003/",
    F"/home/nano01/a/chand133/ThermAI/Dataset/Train/Input/006/",
    F"/home/nano01/a/chand133/ThermAI/Dataset/Train/Input/010/",
    F"/home/nano01/a/chand133/ThermAI/Dataset/Train/Input/020/",
]
train_output_image_paths_root = [
    F"/home/nano01/a/chand133/ThermAI/Dataset/Train/Output_pinn_wo_target/003/",
    F"/home/nano01/a/chand133/ThermAI/Dataset/Train/Output_pinn_wo_target/006/",
    F"/home/nano01/a/chand133/ThermAI/Dataset/Train/Output_pinn_wo_target/010/",
    F"/home/nano01/a/chand133/ThermAI/Dataset/Train/Output_pinn_wo_target/020/",
    F"/home/nano01/a/chand133/ThermAI/Dataset/Train/Output_pinn_wo_target/041/"
]
train_gt_image_paths_root = [
    F"/home/nano01/a/chand133/ThermAI/Dataset/Train/Input/003/",
    F"/home/nano01/a/chand133/ThermAI/Dataset/Train/Input/006/",
    F"/home/nano01/a/chand133/ThermAI/Dataset/Train/Input/010/",
    F"/home/nano01/a/chand133/ThermAI/Dataset/Train/Input/020/",
    F"/home/nano01/a/chand133/ThermAI/Dataset/Train/Input/041/",
]
# Time steps corresponding to the directories
train_time_steps_input = [1, 3, 6, 10, 20]
train_time_steps_output = [3, 6, 10, 20, 41]

test_input_image_paths_root = [
    F"/home/nano01/a/chand133/ThermAI/Dataset/Test/Input/001/",
    F"/home/nano01/a/chand133/ThermAI/Dataset/Test/Input/003/",
    F"/home/nano01/a/chand133/ThermAI/Dataset/Test/Input/006/",
    F"/home/nano01/a/chand133/ThermAI/Dataset/Test/Input/010/",
    F"/home/nano01/a/chand133/ThermAI/Dataset/Test/Input/020/"
]
test_output_image_paths_root = [
    F"/home/nano01/a/chand133/ThermAI/Dataset/Test/Output_pinn_wo_target/003/",
    F"/home/nano01/a/chand133/ThermAI/Dataset/Test/Output_pinn_wo_target/006/",
    F"/home/nano01/a/chand133/ThermAI/Dataset/Test/Output_pinn_wo_target/010/",
    F"/home/nano01/a/chand133/ThermAI/Dataset/Test/Output_pinn_wo_target/020/",
    F"/home/nano01/a/chand133/ThermAI/Dataset/Test/Output_pinn_wo_target/041/"
]
test_gt_image_paths_root = [
    F"/home/nano01/a/chand133/ThermAI/Dataset/Test/Input/003/",
    F"/home/nano01/a/chand133/ThermAI/Dataset/Test/Input/006/",
    F"/home/nano01/a/chand133/ThermAI/Dataset/Test/Input/010/",
    F"/home/nano01/a/chand133/ThermAI/Dataset/Test/Input/020/",
    F"/home/nano01/a/chand133/ThermAI/Dataset/Test/Input/041/"
]
# Time steps corresponding to the directories
test_time_steps_input = [1, 3, 6, 10, 20]
test_time_steps_output = [3, 6, 10, 20, 41]

# Load the updated model state dictionary into the model
model_path = "/home/nano01/a/chand133/ThermAI/PINN/stage_001_to_041_pinn.pth"

epochs= 1000
learning_rate= 1e-6
save_checkpoint= True

amp= False
weight_decay= 1e-8
momentum= 0.999
gradient_clipping= 1.0
alpha = 1e-4  # Thermal diffusivity constant (tune this value)
lambda_reg = 0.1  # Regularization parameter for the physics-informed loss



def main():
    loss_fn = torch.nn.BCEWithLogitsLoss()
    scaler = torch.cuda.amp.GradScaler()
    model = DiffUnet()
    
    if os.path.exists(model_path):
        model.load_state_dict(torch.load(model_path))
        print("Model Loaded Successfully!")

    # move initialised model to chosen device
    model = model.to(device)
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

    # Training
    for idx in range(len(train_time_steps_input)):
        
        patience = 10  # Number of epochs to wait before stopping
        best_score = -float('inf')  # Initialize to the lowest possible value for IOU
        stagnant_epochs = 0  # Counter for epochs without improvement

        if not os.path.exists(train_output_image_paths_root[idx]):
            # print(img_path)
            os.makedirs(train_output_image_paths_root[idx])

        if not os.path.exists(test_output_image_paths_root[idx]):
            # print(img_path)
            os.makedirs(test_output_image_paths_root[idx])

        def flatten(l): return flatten(l[0]) + (flatten(l[1:]) if len(l) > 1 else []) if type(l) is list else [l]

        train_input_image_paths = [] #to store image paths in list
        train_gt_image_paths = []

        for data_path in glob.glob(train_input_image_paths_root[idx] + '/*'):
            train_input_image_paths.append(data_path)

        for data_path in glob.glob(train_gt_image_paths_root[idx] + '/*'):
            train_gt_image_paths.append(data_path)

        train_input_image_paths = sorted(list(flatten(train_input_image_paths)))
        train_gt_image_paths = sorted(list(flatten(train_gt_image_paths)))

        print('train_image_path example: ', train_input_image_paths[0])

        test_input_image_paths = [] #to store image paths in list
        test_gt_image_paths = []

        for data_path in glob.glob(test_input_image_paths_root[idx] + '/*'):
            test_input_image_paths.append(data_path)

        for data_path in glob.glob(test_gt_image_paths_root[idx] + '/*'):
            test_gt_image_paths.append(data_path)

        test_input_image_paths = sorted(list(flatten(test_input_image_paths)))
        test_gt_image_paths = sorted(list(flatten(test_gt_image_paths)))


        print('test_image_path example: ', test_input_image_paths[0])

        # Training
        train_dataset = ThermDataset(train_input_image_paths, train_gt_image_paths,transform_train, study = 'train')
        valid_dataset = ThermDataset(test_input_image_paths, test_gt_image_paths,transform_test, study = 'test')


        batch_size = 100
        train_loader = DataLoader(
            train_dataset, batch_size=batch_size, shuffle=True
        )

        valid_loader = DataLoader(
            valid_dataset, batch_size=4, shuffle=False
        )

        for epoch in range(epochs + 1):
            # print(f"Training epoch {epoch}/{epochs}")
            
            for i, (input_image, output_image, _, _) in enumerate(train_loader):
                input_image = input_image.to(device)
                output_image = output_image.to(device)

                # print(output_image.shape)
                output = model(input_image)

                # Traditional MSE Loss (steady-state output compared to ground truth)
                mse_loss = criterion(output, output_image)

                # Physics-informed loss (based on heat diffusion equation)
                phy_loss = physics_informed_loss(output, alpha, lambda_reg)

                # Total loss: MSE + physics-informed loss
                total_loss = mse_loss + phy_loss

                optimizer.zero_grad()
                total_loss.backward()
                optimizer.step()

            if epoch % 10 == 0:
                print("Index: ", train_time_steps_input[idx])
                print(f"Training epoch {epoch}/{epochs}")
                print(f'Epoch: {epoch}, Batch: {i + 1}, Loss: {total_loss.item():.4f}')

            if epoch % 50 == 0:
                
                score = 0
                total_diff = 0
                model.eval()
                
                with torch.no_grad():
                    for i, (input_image, output_image, _, _) in enumerate(valid_loader):
                        input_image = input_image.to(device)
                        output_image = output_image.to(device)
                        output = model(input_image)
                        
                        output = output[0].detach().cpu().numpy().transpose(1, 2, 0)
                        output = output.clip(0, 1)
                        output = (output * 255.0).astype(np.uint8)

                        input_image = input_image[0].detach().cpu().numpy().transpose(1, 2, 0)
                        input_image = input_image.clip(0, 1)
                        input_image = (input_image * 255.0).astype(np.uint8)
                        
                        output_image = output_image[0].detach().cpu().numpy().transpose(1, 2, 0)
                        output_image = output_image.clip(0, 1)
                        output_image = (output_image * 255.0).astype(np.uint8)
                        
                        diff = test(Image.fromarray(output_image), Image.fromarray(output))
                        total_diff = total_diff + diff
                        iou = calculate_iou_for_single_image(Image.fromarray(input_image), Image.fromarray(output))
                        score = score + iou

                score = score / len(valid_loader)
                total_diff = total_diff / len(valid_loader)
                print("IOU score after: " + str(epoch) + " epochs: " + str(score))
                print("Pixel Diff score after: " + str(epoch) + " epochs: " + str(total_diff))

                # Early stopping logic
                if score > best_score:
                    best_score = score
                    stagnant_epochs = 0
                    # Save the best model
                    torch.save(model.state_dict(), model_path)
                    print(f"New best model saved at epoch {epoch} with IOU: {score}")
                else:
                    stagnant_epochs += 1
                    print(f"No improvement in IOU for {stagnant_epochs} epoch(s)")

                if stagnant_epochs >= patience:
                    print("Early stopping triggered. Training stopped.")
                    break

        print("### Model Summary ###")
        model_size_MB, param_count = get_model_size(model)
        print(f"Model Parameter Size: {model_size_MB:.2f} MB, {param_count} parameters")

        # Inference
        model.eval()
        print("Saving output.")
        # Inference
        train_dataset = ThermDataset2(train_input_image_paths, train_gt_image_paths,transform_train, study = 'train')
        valid_dataset = ThermDataset2(test_input_image_paths, test_gt_image_paths,transform_test, study = 'test')

        batch_size = 1


        train_loader2 = DataLoader(
            train_dataset, batch_size=batch_size, shuffle=True
        )

        valid_loader2 = DataLoader(
            valid_dataset, batch_size=batch_size, shuffle=False
        )
        with torch.no_grad():
            for i, (input_image, output_image, input_image_filepath, output_image_filepath) in enumerate(train_loader2):
        
                filename = input_image_filepath[0].split('/')[-1]
                
                number_str = filename.split('.')[0]
                prefix,suffix = number_str.split('_')
                

                input_image = input_image.to(device)
                output_image = output_image.to(device)
                output = model(input_image)
                
                output = output[0].detach().cpu().numpy().transpose(1, 2, 0)
                # Unnormalize the image
                mean = np.array([0.5, 0.5, 0.5])
                std = np.array([0.5, 0.5, 0.5])
                output = output * std + mean
                
                output = output.clip(0, 1)
                output = (output * 255.0).astype(np.uint8)

                plt.imshow(output)
                plt.axis('off')
                plt.title('')
                # Save the figure
                output_path = f"{train_output_image_paths_root[idx]}{prefix}_{idx}.png"
                plt.savefig(output_path, bbox_inches='tight', pad_inches=0)
                if(i%100) == 0:
                    print(output_path)

            for i, (input_image, output_image, input_image_filepath, output_image_filepath) in enumerate(valid_loader2):
                filename = input_image_filepath[0].split('/')[-1]
                number_str = filename.split('.')[0]
                prefix,suffix = number_str.split('_')

                input_image = input_image.to(device)
                output_image = output_image.to(device)
                output = model(input_image)
                
                output = output[0].detach().cpu().numpy().transpose(1, 2, 0)

                mean = np.array([0.5, 0.5, 0.5])
                std = np.array([0.5, 0.5, 0.5])
                output = output * std + mean

                output = output.clip(0, 1)
                output = (output * 255.0).astype(np.uint8)
                
                plt.imshow(output)
                plt.axis('off')

                # Save the figure
                output_path = f"{test_output_image_paths_root[idx]}{prefix}_{idx}.png"
                plt.savefig(output_path, bbox_inches='tight', pad_inches=0)
                if(i%10) == 0:
                    print(output_path)

if __name__ == '__main__':
    main()