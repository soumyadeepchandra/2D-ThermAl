# -*- coding: utf-8 -*-
"""Therm_UNet.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1V7uuS3JbE0Nianw8ySQ619r2zV66qeqG
"""

import os
import numpy as np # linear algebra
import time
from contextlib import contextmanager # timer
from functools import partial
import glob
# import seaborn as sns

import matplotlib.pylab as plt

# from skimage.transform import rescale, resize
import torch
import torch.nn as nn

#from torch.utils import data
from torch.utils.data import DataLoader, Dataset
import albumentations as A  #####
from tqdm import tqdm

import torch.nn.functional as F
import argparse
import math
import os.path
import shutil

import scipy.io
import torch.nn.parallel

from torch.autograd import Variable
import torch.optim
import cv2
from PIL import Image
import random
import torchvision.transforms as transforms

if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    device = torch.device('cpu')

# transform_train = A.Compose([
#     A.Rotate(limit=45, p=0.5),
#     A.HorizontalFlip(p=0.5),
#     A.Flip(p=0.5),
#     A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.2),
#     A.RandomCrop(width=200, height=200, p=0.5),
#     transforms.Resize((224, 224)),
#     transforms.ToTensor(),
#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
# ])

transform_train = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
])

albumentations_transform = A.Compose([
    A.Rotate(limit=45, p=0.5),
    A.HorizontalFlip(p=0.5),
    A.Flip(p=0.5),
    #A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.2),
    #A.RandomCrop(width=200, height=200, p=0.5),
], additional_targets={"image2": "image"})

transform_test = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
])

def create_image_pairs(folder_path):
    image_pairs_train = []
    image_pairs_test = []
    all_files = sorted(os.listdir(folder_path))  # Ensure the files are sorted
    
    current_prefix = None
    current_series = []
    
    # Loop over the files and create pairs
    for file in all_files:
        if file.endswith(('.jpg', '.png', '.jpeg')):  # Ensure it's an image file
            prefix, _ = file.split('_', 1)
            
            if current_prefix is None:
                current_prefix = prefix
                
            if prefix == current_prefix:
                current_series.append(file)
            else:
                # Create pairs for the current series
                for i in range(len(current_series) - 1):
                    if (int(current_prefix) % 10 == 1):
                        image_pairs_test.append((current_series[i], current_series[i+1]))
                    else:
                        image_pairs_train.append((current_series[i], current_series[i+1]))
                
                # Reset for the next series
                current_prefix = prefix
                current_series = [file]
    
    # Final pair creation for the last series
    for i in range(len(current_series) - 1):
        image_pairs_train.append((current_series[i], current_series[i+1]))
    
    return image_pairs_train, image_pairs_test

folder_path = '/home/nano01/a/chand133/ThermAI/Dataset/Data2'
image_pairs_train, image_pairs_test = create_image_pairs(folder_path)

class ThermDataset(Dataset): # For training
    def __init__(self, image_pairs, transform=False, study='train'):
        self.image_pairs = image_pairs
        self.transform = transform
        self.study = study

    def __len__(self):
        return len(self.image_pairs)

    def __getitem__(self, idx):
        input_image_filepath, output_image_filepath = self.image_pairs[idx]
        directory, filename = os.path.split(input_image_filepath)
        new_directory = os.path.join(directory, 'Dataset', 'Data2')
        input_image_filepath = os.path.join(new_directory, filename)
        directory, filename = os.path.split(output_image_filepath)
        new_directory = os.path.join(directory, 'Dataset', 'Data2')
        output_image_filepath = os.path.join(new_directory, filename)
        image_input = Image.open(input_image_filepath).convert("RGB")
        image_output = Image.open(output_image_filepath).convert("RGB")
        image_input = image_input.resize((224,224))
        image_output = image_output.resize((224,224))

        if self.study == 'train':
            image_np = np.array(image_input)
            image_np2 = np.array(image_output)
            augmented = albumentations_transform(image=image_np, image2=image_np2)
            image_np_transformed = augmented['image']
            image_input = Image.fromarray(image_np_transformed)
            image_np_transformed2 = augmented['image2']
            image_output = Image.fromarray(image_np_transformed2)

        if self.transform is not None:
            image_input = self.transform(image_input)
            image_output = self.transform(image_output)

        return image_input, image_output, input_image_filepath, output_image_filepath

class ThermDataset2(Dataset): # For inference
    def __init__(self, image_pairs, transform=False, study='train'):
        self.image_pairs = image_pairs
        self.transform = transform
        self.study = study

    def __len__(self):
        return len(self.image_pairs)

    def __getitem__(self, idx):
        input_image_filepath, output_image_filepath = self.image_pairs[idx]
        directory, filename = os.path.split(input_image_filepath)
        new_directory = os.path.join(directory, 'Dataset', 'Data2')
        input_image_filepath = os.path.join(new_directory, filename)
        directory, filename = os.path.split(output_image_filepath)
        new_directory = os.path.join(directory, 'Dataset', 'Data2')
        output_image_filepath = os.path.join(new_directory, filename)
        image_input = Image.open(input_image_filepath).convert("RGB")
        image_output = Image.open(output_image_filepath).convert("RGB")
        image_input = image_input.resize((224,224))
        image_output = image_output.resize((224,224))


        # Both input and output are transformed
        if self.transform is not None:
            image_input = self.transform(image_input)
            image_output = self.transform(image_output)

        return image_input, image_output, input_image_filepath, output_image_filepath


def double_conv2d(in_channel, out_channel):
    """
    (convolution => [BN] => ReLU) * 2
    """
    convLayer = nn.Sequential(
        nn.Conv2d(in_channel, out_channel, kernel_size=3, padding=1),
        nn.BatchNorm2d(out_channel),
        nn.ReLU(inplace=True),
        nn.Conv2d(out_channel, out_channel, kernel_size=3, padding=1),
        nn.BatchNorm2d(out_channel),
        nn.ReLU(inplace=True)
    )
    return convLayer


class DiffUnet(nn.Module):
    def __init__(self):
        super(DiffUnet, self).__init__()
        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)

        self.downConvLayer_1 = double_conv2d(3, 48)
        self.downConvLayer_2 = double_conv2d(48, 96)
        self.downConvLayer_3 = double_conv2d(96, 192)
        self.downConvLayer_4 = double_conv2d(192, 384)
        self.downConvLayer_5 = double_conv2d(384, 768)

        self.upTransConv1 = nn.ConvTranspose2d(in_channels=768, out_channels=384, kernel_size=(2, 2), stride=(2, 2))
        self.upConvLayer_1 = double_conv2d(768, 384)

        self.upTransConv2 = nn.ConvTranspose2d(in_channels=384, out_channels=192, kernel_size=(2, 2), stride=(2, 2))
        self.upConvLayer_2 = double_conv2d(384, 192)

        self.upTransConv3 = nn.ConvTranspose2d(in_channels=192, out_channels=96, kernel_size=(2, 2), stride=(2, 2))
        self.upConvLayer_3 = double_conv2d(192, 96)

        self.upTransConv4 = nn.ConvTranspose2d(in_channels=96, out_channels=48, kernel_size=(2, 2), stride=(2, 2))
        self.upConvLayer_4 = double_conv2d(96, 48)

        self.out = nn.Conv2d(in_channels=48, out_channels=3, kernel_size=(1,1)) #out_channels 4 number ta n_classes, 4CH, for 2CH set it=2

    def forward(self, image):
        """
        image shape: batch_size, channel, height, width
        """
        """
        Encoder
        """
        #print(image.shape)
        # Layer1
        d1_out = self.downConvLayer_1(image)
        #print(d1_out.shape)

        # Layer2
        d2_max_pool_out = self.max_pool(d1_out)
        d2_out = self.downConvLayer_2(d2_max_pool_out)
        #print(d2_out.shape)

        # Layer3
        d3_max_pool_out = self.max_pool(d2_out)
        d3_out = self.downConvLayer_3(d3_max_pool_out)
        #print(d1_out.shape)

        # Layer4
        d4_max_pool_out = self.max_pool(d3_out)
        d4_out = self.downConvLayer_4(d4_max_pool_out)
        #print(d4_out.shape)

        # Layer5
        d5_max_pool_out = self.max_pool(d4_out)
        d5_out = self.downConvLayer_5(d5_max_pool_out)
        #print(d5_out.shape)

        """
        Decoder
        """
        up_sampling1 = self.upTransConv1(d5_out)
        u1_out = self.upConvLayer_1(torch.cat([d4_out, up_sampling1], axis=1))
        #print(u1_out.shape)

        up_sampling2 = self.upTransConv2(u1_out)
        u2_out = self.upConvLayer_2(torch.cat([d3_out, up_sampling2], axis=1))
        #print(u2_out.shape)

        up_sampling3 = self.upTransConv3(u2_out)
        u3_out = self.upConvLayer_3(torch.cat([d2_out, up_sampling3], axis=1))
        #print(u3_out.shape)

        up_sampling4 = self.upTransConv4(u3_out)
        u4_out = self.upConvLayer_4(torch.cat([d1_out, up_sampling4], axis=1))
        #print(u4_out.shape)

        final_out = self.out(u4_out)
        #print(final_out.shape)
        return final_out

def test(image_path, output_path):
    # image = Image.open(image_path).convert("RGB")
    # output = Image.open(output_path).convert("RGB")

    # Convert images to numpy arrays
    image1_array = np.array(image_path)
    image2_array = np.array(output_path)

    diff = 0
    # Check if the dimensions are the same
    if image1_array.shape == image2_array.shape:
        # Compute the difference
        difference = np.abs(image1_array - image2_array)
        # print(difference.shape)
        diff = np.sum(difference)/(224*224*3)

    return diff

def calculate_iou_for_single_image(input_image, output_image):
  # Calculate the intersection and union of the two images
  intersection = np.logical_and(input_image, output_image)
  union = np.logical_or(input_image, output_image)

  # Calculate the IOU
  iou = np.sum(intersection) / np.sum(union)

  return iou

def get_model_size(model):
    param_size = 0
    param_count = 0
    for param in model.parameters():
        param_size += param.nelement() * param.element_size()
        param_count += param.nelement()
    param_size_MB = param_size / (1024 ** 2)
    return param_size_MB, param_count


import numpy as np
from skimage.metrics import structural_similarity as ssim

def calculate_ssim_for_single_image(image_path, output_path):
    # Read and resize images
    image1 = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    image1 = cv2.resize(image1, (224, 224), interpolation=cv2.INTER_AREA)
    image2 = cv2.imread(output_path, cv2.IMREAD_GRAYSCALE)
    image2 = cv2.resize(image2, (224, 224), interpolation=cv2.INTER_AREA)
    
    # Ensure that the images are the same size
    if image1.shape != image2.shape:
        raise ValueError("Input images must have the same dimensions")

    # Calculate SSIM
    ssim_index, _ = ssim(image1, image2, full=True)

    return ssim_index

def calculate_rmse_for_single_image(image_path, output_path):
    # Read and resize images
    image1 = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    image1 = cv2.resize(image1, (224, 224), interpolation=cv2.INTER_AREA)
    image2 = cv2.imread(output_path, cv2.IMREAD_GRAYSCALE)
    image2 = cv2.resize(image2, (224, 224), interpolation=cv2.INTER_AREA)
    
    # Ensure that the images are the same size
    if image1.shape != image2.shape:
        raise ValueError("Input images must have the same dimensions")
    
    # Calculate RMSE
    rmse = np.sqrt(np.mean((image1.astype(np.float32) - image2.astype(np.float32)) ** 2))
    
    return rmse

train_output_image_paths_root = F"/home/nano01/a/chand133/ThermAI/Dataset/Train/Output_Pair/"
test_output_image_paths_root = F"/home/nano01/a/chand133/ThermAI/Dataset/Test/Output_Pair/"


# Load the updated model state dictionary into the model
model_path = "/home/nano01/a/chand133/ThermAI/all_stages_early_v2.pth"

if not os.path.exists(train_output_image_paths_root):
    os.makedirs(train_output_image_paths_root)

if not os.path.exists(test_output_image_paths_root):
    os.makedirs(test_output_image_paths_root)


epochs= 100
learning_rate= 1e-6
save_checkpoint= True

amp= False
weight_decay= 1e-8
momentum= 0.999
gradient_clipping= 1.0


# Training
train_dataset = ThermDataset(image_pairs_train, transform_train, study = 'train')
valid_dataset = ThermDataset(image_pairs_test,transform_test, study = 'test')


batch_size = 200
train_loader = DataLoader(
    train_dataset, batch_size=batch_size, shuffle=True
)

valid_loader = DataLoader(
    valid_dataset, batch_size=4, shuffle=False
)

# Inference
train_dataset = ThermDataset2(image_pairs_train,transform_train, study = 'train')
valid_dataset = ThermDataset2(image_pairs_test,transform_test, study = 'test')

batch_size = 1


train_loader2 = DataLoader(
    train_dataset, batch_size=batch_size, shuffle=True
)

valid_loader2 = DataLoader(
    valid_dataset, batch_size=batch_size, shuffle=False
)


def main():
    loss_fn = torch.nn.BCEWithLogitsLoss()
    scaler = torch.cuda.amp.GradScaler()
    model = DiffUnet()
    
    if os.path.exists(model_path):
        model.load_state_dict(torch.load(model_path))
        print("Model Loaded Successfully!")

    # move initialised model to chosen device
    model = model.to(device)
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

    patience = 10  # Number of epochs to wait before stopping after last improvement
    min_delta = 0.01  # Minimum change in the monitored quantity to qualify as an improvement
    best_loss = float('inf')
    epochs_without_improvement = 0

    # Training
    for epoch in range(1, epochs+1):
        # print(f"Training epoch {epoch}/{epochs}")
        for i, (input_image, output_image, _, _) in enumerate(tqdm(train_loader)):
            input_image = input_image.to(device)
            output_image = output_image.to(device)
            # print(output_image.shape)
            output = model(input_image)

            loss = criterion(output, output_image)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

    
        print(f"Training epoch {epoch}/{epochs}")
        print(f'Epoch: {epoch}, Batch: {i+1}, Loss: {loss.item():.4f}')

        if epoch % 10 == 0:
            score = 0
            ssim_score = 0
            rmse_score = 0
            total_diff = 0
            validation_loss = 0  # Initialize validation loss
            model.eval()
            with torch.no_grad():
                for i, (input_image, output_image, _, _) in enumerate(valid_loader):
                    
                    input_image = input_image.to(device)
                    output_image = output_image.to(device)
                    output = model(input_image)
                    
                    val_loss = criterion(output, output_image)  # Calculate validation loss
                    validation_loss += val_loss.item()

                    output = output[0].detach().cpu().numpy().transpose(1, 2, 0)
                    output = output.clip(0, 1)
                    output = (output * 255.0).astype(np.uint8)

                    input_image = input_image[0].detach().cpu().numpy().transpose(1, 2, 0)
                    input_image = input_image.clip(0, 1)
                    input_image = (input_image * 255.0).astype(np.uint8)
                    
                    output_image = output_image[0].detach().cpu().numpy().transpose(1, 2, 0)
                    output_image = output_image.clip(0, 1)
                    output_image = (output_image * 255.0).astype(np.uint8)
                    
                    diff = test(Image.fromarray(output_image), Image.fromarray(output))
                    total_diff = total_diff + diff
                    iou = calculate_iou_for_single_image(Image.fromarray(output_image), Image.fromarray(output))
                    score = score + iou
                    ssim = calculate_ssim_for_single_image(Image.fromarray(output_image), Image.fromarray(output))
                    ssim_score = ssim_score + ssim
                    rmse = calculate_rmse_for_single_image(Image.fromarray(output_image), Image.fromarray(output))
                    rmse_score = rmse_score + rmse

            validation_loss /= len(valid_loader)
            score = score / len(valid_loader)
            ssim_score = ssim_score / len(valid_loader)
            rmse_score = rmse_score / len(valid_loader)
            total_diff = total_diff / len(valid_loader)
            print("IOU score after: " + str(epoch) + " epochs: " + str(score))
            print("SSIM score after: " + str(epoch) + " epochs: " + str(ssim_score))
            print("RMSE score after: " + str(epoch) + " epochs: " + str(rmse_score))
            print("Pixel Diff score after: " + str(epoch) + " epochs: " + str(total_diff))

            if validation_loss < best_loss - min_delta:
                best_loss = validation_loss
                epochs_without_improvement = 0
                # Optionally save the best model here
                torch.save(model.state_dict(), model_path)

            else:
                epochs_without_improvement += 1
                if epochs_without_improvement >= patience:
                    print("Early stopping triggered")
                    break  # Stop training
                
    torch.save(model.state_dict(), model_path)

    print("### Model Summary ###")
    model_size_MB, param_count = get_model_size(model)
    print(f"Model Parameter Size: {model_size_MB:.2f} MB, {param_count} parameters")

    # Inference
    model.eval()
    print("Saving output.")
    with torch.no_grad():
        score = 0
        ssim_score = 0
        rmse_score = 0
        total_diff = 0
        validation_loss = 0 

        for i, (input_image, output_image, input_image_filepath, output_image_filepath) in enumerate(train_loader2):
            # print(input_image_filepath[0])

            filename = input_image_filepath[0].split('/')[-1]
            # print(filename)
            number_str = filename.split('.')[0]
            prefix, suffix = number_str.split('_', 1)
            # number = int(number_str)
            # print(number)

            input_image = input_image.to(device)
            output_image = output_image.to(device)
            output = model(input_image)
            
            output = output[0].detach().cpu().numpy().transpose(1, 2, 0)
            # Unnormalize the image
            mean = np.array([0.5, 0.5, 0.5])
            std = np.array([0.5, 0.5, 0.5])
            output = output * std + mean
            
            output = output.clip(0, 1)
            output = (output * 255.0).astype(np.uint8)
            resized_output = cv2.resize(output, (298, 224))

            diff = test(Image.fromarray(output_image), Image.fromarray(output))
            total_diff = total_diff + diff
            iou = calculate_iou_for_single_image(Image.fromarray(output_image), Image.fromarray(output))
            score = score + iou
            ssim = calculate_ssim_for_single_image(Image.fromarray(output_image), Image.fromarray(output))
            ssim_score = ssim_score + ssim
            rmse = calculate_rmse_for_single_image(Image.fromarray(output_image), Image.fromarray(output))
            rmse_score = rmse_score + rmse

            plt.imshow(output)
            plt.axis('off')
            plt.title('')
            # Save the figure
            file_path = train_output_image_paths_root
            output_path = f"{file_path}/{(prefix)}_{(suffix)}.png"
            plt.savefig(output_path, bbox_inches='tight', pad_inches=0)
            if(i%100) == 0:
                print(output_path)

        validation_loss /= len(train_loader2)
        score = score / len(train_loader2)
        ssim_score = ssim_score / len(train_loader2)
        rmse_score = rmse_score / len(train_loader2)
        total_diff = total_diff / len(train_loader2)
        print("IOU score after: " + str(epoch) + " epochs: " + str(score))
        print("SSIM score after: " + str(epoch) + " epochs: " + str(ssim_score))
        print("RMSE score after: " + str(epoch) + " epochs: " + str(rmse_score))
        print("Pixel Diff score after: " + str(epoch) + " epochs: " + str(total_diff))

        score = 0
        ssim_score = 0
        rmse_score = 0
        total_diff = 0
        validation_loss = 0 

        for i, (input_image, output_image, input_image_filepath, output_image_filepath) in enumerate(valid_loader2):
            filename = input_image_filepath[0].split('/')[-1]
            number_str = filename.split('.')[0]
            prefix, suffix = number_str.split('_', 1)
            # number = (number_str)

            input_image = input_image.to(device)
            output_image = output_image.to(device)
            output = model(input_image)
            
            output = output[0].detach().cpu().numpy().transpose(1, 2, 0)

            mean = np.array([0.5, 0.5, 0.5])
            std = np.array([0.5, 0.5, 0.5])
            output = output * std + mean

            output = output.clip(0, 1)
            output = (output * 255.0).astype(np.uint8)
            resized_output = cv2.resize(output, (298, 224))
            
            diff = test(Image.fromarray(output_image), Image.fromarray(output))
            total_diff = total_diff + diff
            iou = calculate_iou_for_single_image(Image.fromarray(output_image), Image.fromarray(output))
            score = score + iou
            ssim = calculate_ssim_for_single_image(Image.fromarray(output_image), Image.fromarray(output))
            ssim_score = ssim_score + ssim
            rmse = calculate_rmse_for_single_image(Image.fromarray(output_image), Image.fromarray(output))
            rmse_score = rmse_score + rmse

            plt.imshow(output)
            plt.axis('off')

            # Save the figure
            file_path = test_output_image_paths_root
            output_path = f"{file_path}/{(prefix)}_{(suffix)}.png"
            plt.savefig(output_path, bbox_inches='tight', pad_inches=0)
            if(i%10) == 0:
                print(output_path)

        validation_loss /= len(valid_loader2)
        score = score / len(valid_loader2)
        ssim_score = ssim_score / len(valid_loader2)
        rmse_score = rmse_score / len(valid_loader2)
        total_diff = total_diff / len(valid_loader2)
        print("IOU score after: " + str(epoch) + " epochs: " + str(score))
        print("SSIM score after: " + str(epoch) + " epochs: " + str(ssim_score))
        print("RMSE score after: " + str(epoch) + " epochs: " + str(rmse_score))
        print("Pixel Diff score after: " + str(epoch) + " epochs: " + str(total_diff))




if __name__ == '__main__':
    main()

