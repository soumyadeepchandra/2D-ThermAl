# -*- coding: utf-8 -*-
"""Therm_UNet.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1V7uuS3JbE0Nianw8ySQ619r2zV66qeqG
"""

import os
import numpy as np # linear algebra
import time
from contextlib import contextmanager # timer
from functools import partial
import glob
# import seaborn as sns

import matplotlib.pylab as plt

# from skimage.transform import rescale, resize
import torch
import torch.nn as nn

#from torch.utils import data
from torch.utils.data import DataLoader, Dataset
import albumentations as A  #####


import torch.nn.functional as F
import argparse
import math
import os.path
import shutil

import scipy.io
import torch.nn.parallel

from torch.autograd import Variable
import torch.optim

from PIL import Image
import random
import torchvision.transforms as transforms

if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    device = torch.device('cpu')

# transform_train = A.Compose([
#     A.Rotate(limit=45, p=0.5),
#     A.HorizontalFlip(p=0.5),
#     A.Flip(p=0.5),
#     A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.2),
#     A.RandomCrop(width=200, height=200, p=0.5),
#     transforms.Resize((224, 224)),
#     transforms.ToTensor(),
#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
# ])

transform_train = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
])

albumentations_transform = A.Compose([
    A.Rotate(limit=45, p=0.5),
    A.HorizontalFlip(p=0.5),
    A.Flip(p=0.5),
    #A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.2),
    #A.RandomCrop(width=200, height=200, p=0.5),
], additional_targets={"image2": "image"})

transform_test = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
])

class ThermDataset(Dataset): #For training
    def __init__(self, input_image_paths, gt_image_paths, transform=False, study = 'train'): #transform = true in train, false in test
        self.input_image_paths = input_image_paths
        self.gt_image_paths = gt_image_paths
        self.transform = transform
        self.study = study
        # print(self.input_image_paths)

    def __len__(self):
        return len(self.input_image_paths)

    #idx is handled auto, u dont need to specify
    def __getitem__(self, idx):
        input_image_filepath = self.input_image_paths[idx]
        output_image_filepath = self.gt_image_paths[idx]
        image_input = Image.open(input_image_filepath).convert("RGB")
        image_output = Image.open(output_image_filepath).convert("RGB")
        image_input = image_input.resize((224,224))
        image_output = image_output.resize((224,224))
        # print(input_image_filepath)
        # print(output_image_filepath)
        # print(image_output.shape)

        if self.study == 'train':
            image_np = np.array(image_input)
            image_np2 = np.array(image_output)
            augmented = albumentations_transform(image=image_np, image2=image_np2)
            image_np_transformed = augmented['image']
            image_input = Image.fromarray(image_np_transformed)
            image_np_transformed2 = augmented['image2']
            image_output = Image.fromarray(image_np_transformed2)


        # Both input and output are transformed
        if self.transform is not None:
            image_input = self.transform(image_input)
            image_output = self.transform(image_output)
            
        return image_input, image_output, input_image_filepath, output_image_filepath

class ThermDataset2(Dataset): # For inference
    def __init__(self, input_image_paths, gt_image_paths, transform=False, study = 'train'): #transform = true in train, false in test
        self.input_image_paths = input_image_paths
        self.gt_image_paths = gt_image_paths
        self.transform = transform
        self.study = study
        # print(self.input_image_paths)

    def __len__(self):
        return len(self.input_image_paths)

    #idx is handled auto, u dont need to specify
    def __getitem__(self, idx):
        input_image_filepath = self.input_image_paths[idx]
        output_image_filepath = self.gt_image_paths[idx]
        image_input = Image.open(input_image_filepath).convert("RGB")
        image_output = Image.open(output_image_filepath).convert("RGB")
        image_input = image_input.resize((224,224))
        image_output = image_output.resize((224,224))


        # Both input and output are transformed
        if self.transform is not None:
            image_input = self.transform(image_input)
            image_output = self.transform(image_output)

        return image_input, image_output, input_image_filepath, output_image_filepath


def double_conv2d(in_channel, out_channel):
    """
    (convolution => [BN] => ReLU) * 2
    """
    convLayer = nn.Sequential(
        nn.Conv2d(in_channel, out_channel, kernel_size=3, padding=1),
        nn.BatchNorm2d(out_channel),
        nn.ReLU(inplace=True),
        nn.Conv2d(out_channel, out_channel, kernel_size=3, padding=1),
        nn.BatchNorm2d(out_channel),
        nn.ReLU(inplace=True)
    )
    return convLayer


class DiffUnet(nn.Module):
    def __init__(self):
        super(DiffUnet, self).__init__()
        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)

        self.downConvLayer_1 = double_conv2d(3, 48)
        self.downConvLayer_2 = double_conv2d(48, 96)
        self.downConvLayer_3 = double_conv2d(96, 192)
        self.downConvLayer_4 = double_conv2d(192, 384)
        self.downConvLayer_5 = double_conv2d(384, 768)

        self.upTransConv1 = nn.ConvTranspose2d(in_channels=768, out_channels=384, kernel_size=(2, 2), stride=(2, 2))
        self.upConvLayer_1 = double_conv2d(768, 384)

        self.upTransConv2 = nn.ConvTranspose2d(in_channels=384, out_channels=192, kernel_size=(2, 2), stride=(2, 2))
        self.upConvLayer_2 = double_conv2d(384, 192)

        self.upTransConv3 = nn.ConvTranspose2d(in_channels=192, out_channels=96, kernel_size=(2, 2), stride=(2, 2))
        self.upConvLayer_3 = double_conv2d(192, 96)

        self.upTransConv4 = nn.ConvTranspose2d(in_channels=96, out_channels=48, kernel_size=(2, 2), stride=(2, 2))
        self.upConvLayer_4 = double_conv2d(96, 48)

        self.out = nn.Conv2d(in_channels=48, out_channels=3, kernel_size=(1,1)) #out_channels 4 number ta n_classes, 4CH, for 2CH set it=2

    def forward(self, image):
        """
        image shape: batch_size, channel, height, width
        """
        """
        Encoder
        """
        #print(image.shape)
        # Layer1
        d1_out = self.downConvLayer_1(image)
        #print(d1_out.shape)

        # Layer2
        d2_max_pool_out = self.max_pool(d1_out)
        d2_out = self.downConvLayer_2(d2_max_pool_out)
        #print(d2_out.shape)

        # Layer3
        d3_max_pool_out = self.max_pool(d2_out)
        d3_out = self.downConvLayer_3(d3_max_pool_out)
        #print(d1_out.shape)

        # Layer4
        d4_max_pool_out = self.max_pool(d3_out)
        d4_out = self.downConvLayer_4(d4_max_pool_out)
        #print(d4_out.shape)

        # Layer5
        d5_max_pool_out = self.max_pool(d4_out)
        d5_out = self.downConvLayer_5(d5_max_pool_out)
        #print(d5_out.shape)

        """
        Decoder
        """
        up_sampling1 = self.upTransConv1(d5_out)
        u1_out = self.upConvLayer_1(torch.cat([d4_out, up_sampling1], axis=1))
        #print(u1_out.shape)

        up_sampling2 = self.upTransConv2(u1_out)
        u2_out = self.upConvLayer_2(torch.cat([d3_out, up_sampling2], axis=1))
        #print(u2_out.shape)

        up_sampling3 = self.upTransConv3(u2_out)
        u3_out = self.upConvLayer_3(torch.cat([d2_out, up_sampling3], axis=1))
        #print(u3_out.shape)

        up_sampling4 = self.upTransConv4(u3_out)
        u4_out = self.upConvLayer_4(torch.cat([d1_out, up_sampling4], axis=1))
        #print(u4_out.shape)

        final_out = self.out(u4_out)
        #print(final_out.shape)
        return final_out

def test(image_path, output_path):
    # image = Image.open(image_path).convert("RGB")
    # output = Image.open(output_path).convert("RGB")

    # Convert images to numpy arrays
    image1_array = np.array(image_path)
    image2_array = np.array(output_path)

    diff = 0
    # Check if the dimensions are the same
    if image1_array.shape == image2_array.shape:
        # Compute the difference
        difference = np.abs(image1_array - image2_array)
        # print(difference.shape)
        diff = np.sum(difference)/(224*224*3)

    return diff

def calculate_iou_for_single_image(input_image, output_image):
  # Calculate the intersection and union of the two images
  intersection = np.logical_and(input_image, output_image)
  union = np.logical_or(input_image, output_image)

  # Calculate the IOU
  iou = np.sum(intersection) / np.sum(union)

  return iou

def get_model_size(model):
    param_size = 0
    param_count = 0
    for param in model.parameters():
        param_size += param.nelement() * param.element_size()
        param_count += param.nelement()
    param_size_MB = param_size / (1024 ** 2)
    return param_size_MB, param_count

# 001->003->006->010->020->041
############################# Stage 4 -> 010 to 020 #######################################
train_input_image_paths_root = F"/home/nano01/a/chand133/ThermAI/Dataset/Train/Input/010/"
train_output1_image_paths_root = F"/home/nano01/a/chand133/ThermAI/Dataset/Train/Output/020/"
train_gt_image_paths_root = F"/home/nano01/a/chand133/ThermAI/Dataset/Train/Input/020/"

test_input_image_paths_root = F"/home/nano01/a/chand133/ThermAI/Dataset/Test/Input/010/"
test_output1_image_paths_root = F"/home/nano01/a/chand133/ThermAI/Dataset/Test/Output/020/"
test_gt_image_paths_root = F"/home/nano01/a/chand133/ThermAI/Dataset/Test/Input/020/"

# Load the updated model state dictionary into the model
model_path = "/home/nano01/a/chand133/ThermAI/stage_010_to_020.pth"

if not os.path.exists(train_output1_image_paths_root):
    # print(img_path)
    os.makedirs(train_output1_image_paths_root)

if not os.path.exists(test_output1_image_paths_root):
    # print(img_path)
    os.makedirs(test_output1_image_paths_root)

def flatten(l): return flatten(l[0]) + (flatten(l[1:]) if len(l) > 1 else []) if type(l) is list else [l]

train_input_image_paths = [] #to store image paths in list
train_gt_image_paths = []

for data_path in glob.glob(train_input_image_paths_root + '/*'):
    train_input_image_paths.append(data_path)

for data_path in glob.glob(train_gt_image_paths_root + '/*'):
    train_gt_image_paths.append(data_path)

train_input_image_paths = sorted(list(flatten(train_input_image_paths)))
train_gt_image_paths = sorted(list(flatten(train_gt_image_paths)))

print('train_image_path example: ', train_input_image_paths[0])

test_input_image_paths = [] #to store image paths in list
test_gt_image_paths = []

for data_path in glob.glob(test_input_image_paths_root + '/*'):
    test_input_image_paths.append(data_path)

for data_path in glob.glob(test_gt_image_paths_root + '/*'):
    test_gt_image_paths.append(data_path)

test_input_image_paths = sorted(list(flatten(test_input_image_paths)))
test_gt_image_paths = sorted(list(flatten(test_gt_image_paths)))


print('test_image_path example: ', test_input_image_paths[0])
# print('test_image_path example: ', test_gt_image_paths)


epochs= 2000
learning_rate= 1e-6
save_checkpoint= True

amp= False
weight_decay= 1e-8
momentum= 0.999
gradient_clipping= 1.0


# Training
train_dataset = ThermDataset(train_input_image_paths, train_gt_image_paths,transform_train, study = 'train')
valid_dataset = ThermDataset(test_input_image_paths, test_gt_image_paths,transform_test, study = 'test')


batch_size = 100
train_loader = DataLoader(
    train_dataset, batch_size=batch_size, shuffle=True
)

valid_loader = DataLoader(
    valid_dataset, batch_size=4, shuffle=False
)

# Inference
train_dataset = ThermDataset2(train_input_image_paths, train_gt_image_paths,transform_train, study = 'train')
valid_dataset = ThermDataset2(test_input_image_paths, test_gt_image_paths,transform_test, study = 'test')

batch_size = 1


train_loader2 = DataLoader(
    train_dataset, batch_size=batch_size, shuffle=True
)

valid_loader2 = DataLoader(
    valid_dataset, batch_size=batch_size, shuffle=False
)

def main():
    loss_fn = torch.nn.BCEWithLogitsLoss()
    scaler = torch.cuda.amp.GradScaler()
    model = DiffUnet()
    
    if os.path.exists(model_path):
        model.load_state_dict(torch.load(model_path))
        print("Model Loaded Successfully!")

    # move initialised model to chosen device
    model = model.to(device)
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

    # Training
    # for epoch in range(1, epochs+1):
    #     # print(f"Training epoch {epoch}/{epochs}")
    #     for i, (input_image, output_image, _, _) in enumerate(train_loader):
    #         input_image = input_image.to(device)
    #         output_image = output_image.to(device)
    #         # print(output_image.shape)
    #         output = model(input_image)

    #         loss = criterion(output, output_image)

    #         optimizer.zero_grad()
    #         loss.backward()
    #         optimizer.step()

    #     if epoch % 10 == 0:
    #         print(f"Training epoch {epoch}/{epochs}")
    #         print(f'Epoch: {epoch}, Batch: {i+1}, Loss: {loss.item():.4f}')

    #     if epoch % 100 == 0:
    #         score = 0
    #         total_diff = 0
    #         model.eval()
    #         with torch.no_grad():
    #             for i, (input_image, output_image, _, _) in enumerate(valid_loader):
                    
    #                 input_image = input_image.to(device)
    #                 output_image = output_image.to(device)
    #                 output = model(input_image)
                    
    #                 output = output[0].detach().cpu().numpy().transpose(1, 2, 0)
    #                 output = output.clip(0, 1)
    #                 output = (output * 255.0).astype(np.uint8)

    #                 input_image = input_image[0].detach().cpu().numpy().transpose(1, 2, 0)
    #                 input_image = input_image.clip(0, 1)
    #                 input_image = (input_image * 255.0).astype(np.uint8)
                    
    #                 output_image = output_image[0].detach().cpu().numpy().transpose(1, 2, 0)
    #                 output_image = output_image.clip(0, 1)
    #                 output_image = (output_image * 255.0).astype(np.uint8)
                    
    #                 diff = test(Image.fromarray(output_image), Image.fromarray(output))
    #                 total_diff = total_diff + diff
    #                 iou = calculate_iou_for_single_image(Image.fromarray(input_image), Image.fromarray(output))
    #                 score = score + iou

    #         score = score / len(valid_loader)
    #         total_diff = total_diff / len(valid_loader)
    #         print("IOU score after: " + str(epoch) + " epochs: " + str(score))
    #         print("Pixel Diff score after: " + str(epoch) + " epochs: " + str(total_diff))

    # torch.save(model.state_dict(), model_path)

    print("### Model Summary ###")
    model_size_MB, param_count = get_model_size(model)
    print(f"Model Parameter Size: {model_size_MB:.2f} MB, {param_count} parameters")

    # Inference
    model.eval()
    print("Saving output.")
    with torch.no_grad():
        for i, (input_image, output_image, input_image_filepath, output_image_filepath) in enumerate(train_loader2):
            # print(input_image_filepath[0])

            filename = input_image_filepath[0].split('/')[-1]
            # print(filename)
            number_str = filename.split('.')[0]
            prefix,suffix = number_str.split('_')
            # print(number)

            input_image = input_image.to(device)
            output_image = output_image.to(device)
            output = model(input_image)
            
            output = output[0].detach().cpu().numpy().transpose(1, 2, 0)
            # Unnormalize the image
            mean = np.array([0.5, 0.5, 0.5])
            std = np.array([0.5, 0.5, 0.5])
            output = output * std + mean
            
            output = output.clip(0, 1)
            output = (output * 255.0).astype(np.uint8)

            plt.imshow(output)
            plt.axis('off')
            plt.title('')
            # Save the figure
            output_path = f"{train_output1_image_paths_root}{prefix}_020.png"
            plt.savefig(output_path, bbox_inches='tight', pad_inches=0)
            if(i%100) == 0:
                print(output_path)

        for i, (input_image, output_image, input_image_filepath, output_image_filepath) in enumerate(valid_loader2):
            filename = input_image_filepath[0].split('/')[-1]
            number_str = filename.split('.')[0]
            prefix,suffix = number_str.split('_')

            input_image = input_image.to(device)
            output_image = output_image.to(device)
            output = model(input_image)
            
            output = output[0].detach().cpu().numpy().transpose(1, 2, 0)

            mean = np.array([0.5, 0.5, 0.5])
            std = np.array([0.5, 0.5, 0.5])
            output = output * std + mean

            output = output.clip(0, 1)
            output = (output * 255.0).astype(np.uint8)
            
            plt.imshow(output)
            plt.axis('off')

            # Save the figure
            output_path = f"{test_output1_image_paths_root}{prefix}_020.png"
            plt.savefig(output_path, bbox_inches='tight', pad_inches=0)
            print(output_path)



if __name__ == '__main__':
    main()

